{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJa1VUi6C8Vz",
        "outputId": "df7fc2df-7571-4ae4-9880-de2731f51519"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af4CG6BhD-0p",
        "outputId": "dccc7b60-b462-4f19-8ce3-57631281a5e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, learning_curve, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, precision_recall_curve\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE, mutual_info_classif\n",
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#ff9896', '#98df8a']\n",
        "sns.set_palette(sns.color_palette(colors))"
      ],
      "metadata": {
        "id": "2jP2UEyrC9VV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"\n",
        "    Load and preprocess the disease dataset\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)  # Load the actual dataset\n",
        "\n",
        "    # Check for missing values\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(f\"Missing values: {missing_values.sum()}\")\n",
        "\n",
        "    # Check for class imbalance\n",
        "    class_distribution = df['prognosis'].value_counts()\n",
        "    print(\"\\nClass distribution:\")\n",
        "    print(class_distribution)\n",
        "\n",
        "    # Plot class distribution\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    ax = sns.countplot(x='prognosis', data=df)\n",
        "    plt.title('Disease Class Distribution', fontsize=16)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('prognosis', axis=1)\n",
        "    y = df['prognosis']\n",
        "\n",
        "    # Print feature characteristics for understanding binary nature\n",
        "    print(\"\\nFeature value distribution (top 5 features):\")\n",
        "    for col in X.columns[:5]:\n",
        "        print(f\"{col}: {X[col].value_counts().to_dict()}\")\n",
        "\n",
        "    return X, y, df\n"
      ],
      "metadata": {
        "id": "xHV6MNCGC9YZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def feature_selection_with_mutual_info(X, y, top_n=30):\n",
        "    \"\"\"\n",
        "    Select top N features using Mutual Information\n",
        "    \"\"\"\n",
        "    mutual_info = mutual_info_classif(X, y)\n",
        "    feature_scores = pd.Series(mutual_info, index=X.columns)\n",
        "\n",
        "    # Select the top N features based on the mutual information score\n",
        "    top_features = feature_scores.nlargest(top_n).index.tolist()\n",
        "    print(f\"Top {top_n} selected features based on Mutual Information:\")\n",
        "    for i, feature in enumerate(top_features, 1):\n",
        "        print(f\"{i}. {feature} (Score: {feature_scores[feature]:.4f})\")\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    feature_scores.nlargest(top_n).sort_values().plot(kind='barh')\n",
        "    plt.title(f'Top {top_n} Features by Mutual Information', fontsize=16)\n",
        "    plt.xlabel('Mutual Information Score', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return X[top_features], top_features"
      ],
      "metadata": {
        "id": "BF2_e6zzC9a-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_class_imbalance(X, y, method='combined'):\n",
        "    \"\"\"\n",
        "    Handle class imbalance using various techniques\n",
        "    \"\"\"\n",
        "    if method == 'none':\n",
        "        return X, y\n",
        "\n",
        "    if method == 'smote':\n",
        "        print(\"Applying SMOTE to handle class imbalance...\")\n",
        "        sampler = SMOTE(random_state=42, k_neighbors=5)\n",
        "    elif method == 'adasyn':\n",
        "        print(\"Applying ADASYN to handle class imbalance...\")\n",
        "        sampler = ADASYN(random_state=42, n_neighbors=5)\n",
        "    elif method == 'undersample':\n",
        "        print(\"Applying Random Undersampling to handle class imbalance...\")\n",
        "        sampler = RandomUnderSampler(random_state=42)\n",
        "    elif method == 'combined':\n",
        "        print(\"Applying combined sampling approach...\")\n",
        "\n",
        "        # First apply undersampling to extreme majority classes\n",
        "        class_counts = pd.Series(y).value_counts()\n",
        "        max_count = class_counts.max()\n",
        "        min_count = class_counts.min()\n",
        "\n",
        "        if max_count / min_count > 10:\n",
        "            print(\"Detected extreme imbalance. First applying undersampling...\")\n",
        "            under_sampler = RandomUnderSampler(\n",
        "                sampling_strategy={cls: min(count, max_count // 5) for cls, count in class_counts.items() if count > max_count // 2},\n",
        "                random_state=42\n",
        "            )\n",
        "            X, y = under_sampler.fit_resample(X, y)\n",
        "\n",
        "        print(\"Applying SMOTE for final balancing...\")\n",
        "        sampler = SMOTE(random_state=42, k_neighbors=min(5, min_count-1))\n",
        "\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    print(f\"Shape before resampling: {X.shape}\")\n",
        "    print(f\"Shape after resampling: {X_resampled.shape}\")\n",
        "\n",
        "    # Plot the resampled class distribution\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    sns.countplot(x=y_resampled)\n",
        "    plt.title('Resampled Class Distribution', fontsize=16)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('resampled_class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return X_resampled, y_resampled"
      ],
      "metadata": {
        "id": "472Psi-DC9ds"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_list():\n",
        "    \"\"\"\n",
        "    Create a list of models suitable for binary features with categorical targets\n",
        "    \"\"\"\n",
        "    model_list = [\n",
        "        ('Logistic Regression', LogisticRegression(C=1.0, solver='saga', penalty='l2', max_iter=2000, class_weight='balanced', random_state=42)),\n",
        "        ('Random Forest', RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', bootstrap=True, class_weight='balanced', oob_score=True, random_state=42)),\n",
        "        ('XGBoost', XGBClassifier(learning_rate=0.05, n_estimators=200, max_depth=6, objective='multi:softprob', subsample=0.8, colsample_bytree=0.8, gamma=0.1, min_child_weight=1, use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
        "        ('Decision Tree', DecisionTreeClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=2, criterion='entropy', class_weight='balanced', random_state=42)),\n",
        "        ('SVM', SVC(C=10.0, kernel='rbf', gamma='scale', decision_function_shape='ovr', probability=True, class_weight='balanced', random_state=42)),\n",
        "        ('Gradient Boosting', GradientBoostingClassifier(learning_rate=0.05, n_estimators=200, max_depth=5, min_samples_split=10, subsample=0.8, random_state=42)),\n",
        "        # New models good for binary features\n",
        "        ('Bernoulli NB', BernoulliNB(alpha=1.0)),  # Specifically designed for binary features\n",
        "        ('KNN', KNeighborsClassifier(n_neighbors=5, weights='distance', metric='hamming')), # Hamming distance for binary features\n",
        "        ('AdaBoost', AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
        "        ('Extra Trees', ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_split=5, class_weight='balanced', random_state=42)),\n",
        "        ('Ridge Classifier', RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42)),\n",
        "        ('MLP Neural Network', MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', alpha=0.0001, max_iter=500, random_state=42)),\n",
        "        ('LightGBM', LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, max_depth=-1, random_state=42, verbose=-1)),\n",
        "        ('CatBoost', CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, loss_function='MultiClass', random_state=42, verbose=0)),\n",
        "        ('Voting Classifier', VotingClassifier(estimators=[\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "            ('xgb', XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
        "            ('lgbm', LGBMClassifier(n_estimators=100, random_state=42, verbose=-1))\n",
        "        ], voting='soft', n_jobs=-1))\n",
        "    ]\n",
        "\n",
        "    return model_list\n"
      ],
      "metadata": {
        "id": "QYxtHtmvC9gP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_top_models(X_train, X_val, y_train, y_val, top_features, top_n=5):\n",
        "    \"\"\"\n",
        "    Train and evaluate the top N models based on accuracy.\n",
        "    \"\"\"\n",
        "    model_list = create_model_list()\n",
        "    model_list.append(('Stacking Ensemble', create_stacking_model()))\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train and evaluate models\n",
        "    for name, model in model_list:\n",
        "        # Training time\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        # Inference time\n",
        "        start_time = time.time()\n",
        "        y_pred = model.predict(X_val)\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_prob = model.predict_proba(X_val)\n",
        "        else:\n",
        "            y_prob = np.zeros((len(y_val), len(np.unique(y_val))))\n",
        "            for i, pred in enumerate(y_pred):\n",
        "                y_prob[i, pred] = 1\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        # Evaluate metrics\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        precision = precision_score(y_val, y_pred, average='weighted')\n",
        "        recall = recall_score(y_val, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "\n",
        "        try:\n",
        "            auc_score = roc_auc_score(y_val, y_prob, multi_class='ovr', average='macro')\n",
        "        except Exception as e:\n",
        "            auc_score = 0.0\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'auc': auc_score,\n",
        "            'train_time': train_time,\n",
        "            'inference_time': inference_time,\n",
        "            'y_pred': y_pred,\n",
        "            'y_prob': y_prob,\n",
        "            'model': model\n",
        "        }\n",
        "\n",
        "    # Sort results by accuracy and select the top N models\n",
        "    sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
        "    top_results = sorted_results[:top_n]\n",
        "\n",
        "    # Plot the learning curves (Training vs Validation)\n",
        "    plot_learning_curves_for_top_models(top_results, X_train, y_train)\n",
        "\n",
        "    return top_results\n"
      ],
      "metadata": {
        "id": "JnymP4naC9i2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves_for_top_models(top_results, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Plot the learning curves for the top N models based on accuracy.\n",
        "    \"\"\"\n",
        "    for model_name, model_results in top_results:\n",
        "        model = model_results['model']\n",
        "\n",
        "        # Calculate learning curves\n",
        "        train_sizes, train_scores, val_scores = learning_curve(\n",
        "            model, X_train, y_train,\n",
        "            train_sizes=np.linspace(0.1, 1.0, 5), cv=5,\n",
        "            scoring='accuracy', n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Mean and std\n",
        "        train_mean = np.mean(train_scores, axis=1)\n",
        "        train_std = np.std(train_scores, axis=1)\n",
        "        val_mean = np.mean(val_scores, axis=1)\n",
        "        val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_sizes, train_mean, 'o-', label='Training Score', color=colors[0])\n",
        "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=colors[0])\n",
        "\n",
        "        plt.plot(train_sizes, val_mean, 'o-', label='Validation Score', color=colors[1])\n",
        "        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=colors[1])\n",
        "\n",
        "        plt.title(f'Learning Curves - {model_name}', fontsize=16)\n",
        "        plt.xlabel('Training Set Size', fontsize=14)\n",
        "        plt.ylabel('Accuracy', fontsize=14)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.legend(loc='best', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'learning_curve_{model_name}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "A-FI1cCaC9lI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_disease_classification_pipeline(file_path):\n",
        "    \"\"\"\n",
        "    Main pipeline function to run the entire disease classification workflow\n",
        "    \"\"\"\n",
        "    print(\"=== Starting Disease Classification Pipeline ===\")\n",
        "\n",
        "    # Step 1: Load and preprocess data\n",
        "    print(\"\\n=== Loading and Preprocessing Data ===\")\n",
        "    X, y, df = load_and_preprocess_data(file_path)\n",
        "\n",
        "    # Step 2: Feature selection\n",
        "    print(\"\\n=== Performing Feature Selection ===\")\n",
        "    X_selected, top_features = feature_selection_with_mutual_info(X, y, top_n=30)\n",
        "\n",
        "    # Step 3: Handle class imbalance\n",
        "    print(\"\\n=== Handling Class Imbalance ===\")\n",
        "    X_balanced, y_balanced = handle_class_imbalance(X_selected, y, method='combined')\n",
        "\n",
        "    # Step 4: Split data into train and validation sets\n",
        "    print(\"\\n=== Splitting Data into Train and Validation Sets ===\")\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.15, random_state=42, stratify=y_balanced)\n",
        "\n",
        "    # Encode target labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "    # Step 5: Train and evaluate top models\n",
        "    print(\"\\n=== Training and Evaluating Models ===\")\n",
        "    top_models = train_and_evaluate_top_models(X_train, X_val, y_train_encoded, y_val_encoded, top_features, top_n=5)\n",
        "\n",
        "    return top_models\n"
      ],
      "metadata": {
        "id": "zwF9jWjeC9n5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_stacking_model():\n",
        "    \"\"\"\n",
        "    Create an optimized stacking ensemble model specifically for binary features\n",
        "    \"\"\"\n",
        "    base_models = [\n",
        "        ('lr', LogisticRegression(C=1.0, solver='saga', penalty='l2', max_iter=1000, random_state=42)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', class_weight='balanced', random_state=42)),\n",
        "        ('xgb', XGBClassifier(learning_rate=0.05, n_estimators=200, max_depth=6, subsample=0.8, colsample_bytree=0.8, gamma=0.1, min_child_weight=1, use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
        "        ('bnb', BernoulliNB(alpha=1.0)),  # Adding Bernoulli NB as it's good for binary features\n",
        "        ('et', ExtraTreesClassifier(n_estimators=200, max_depth=10, random_state=42))\n",
        "    ]\n",
        "\n",
        "    # Meta-model (final estimator)\n",
        "    meta_model = LogisticRegression(C=1.0, solver='saga', max_iter=1000, random_state=42)\n",
        "\n",
        "    # Stacking model\n",
        "    stacking_model = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta_model,\n",
        "        cv=5,\n",
        "        stack_method='predict_proba',\n",
        "        n_jobs=-1,\n",
        "        passthrough=True\n",
        "    )\n",
        "\n",
        "    return stacking_model"
      ],
      "metadata": {
        "id": "plwxh7dBC9p6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c3wlhEfCSbM",
        "outputId": "98c6bd71-9020-4711-c139-cce289ba3638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting Disease Classification Pipeline ===\n",
            "\n",
            "=== Loading and Preprocessing Data ===\n",
            "Missing values: 0\n",
            "\n",
            "Class distribution:\n",
            "prognosis\n",
            "Fungal Infection                 121\n",
            "Allergy                          121\n",
            "GERD                             121\n",
            "Chronic Cholestasis              121\n",
            "Drug Reaction                    121\n",
            "Peptic Ulcer Disease             121\n",
            "AIDS                             121\n",
            "Diabetes                         121\n",
            "Gastroenteritis                  121\n",
            "Bronchial Asthma                 121\n",
            "Hypertension                     121\n",
            "Migraine                         121\n",
            "Cervical Spondylosis             121\n",
            "Paralysis (brain hemorrhage)     121\n",
            "Jaundice                         121\n",
            "Malaria                          121\n",
            "Chickenpox                       121\n",
            "Dengue                           121\n",
            "Typhoid                          121\n",
            "Hepatitis A                      121\n",
            "Hepatitis B                      121\n",
            "Hepatitis C                      121\n",
            "Hepatitis D                      121\n",
            "Hepatitis E                      121\n",
            "Alcoholic Hepatitis              121\n",
            "Tuberculosis                     121\n",
            "Common Cold                      121\n",
            "Pneumonia                        121\n",
            "Dimorphic Hemmorhoids (piles)    121\n",
            "Heart Attack                     121\n",
            "Varicose Veins                   121\n",
            "Hypothyroidism                   121\n",
            "Hyperthyroidism                  121\n",
            "Hypoglycemia                     121\n",
            "Osteoarthritis                   121\n",
            "Arthritis                        121\n",
            "Vertigo                          121\n",
            "Acne                             121\n",
            "Urinary Tract Infection          121\n",
            "Psoriasis                        121\n",
            "Impetigo                         121\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Feature value distribution (top 5 features):\n",
            "itching: {0: 4277, 1: 684}\n",
            "skin_rash: {0: 4168, 1: 793}\n",
            "nodal_skin_eruptions: {0: 4852, 1: 109}\n",
            "continuous_sneezing: {0: 4737, 1: 224}\n",
            "shivering: {0: 4852, 1: 109}\n",
            "\n",
            "=== Performing Feature Selection ===\n",
            "Top 30 selected features based on Mutual Information:\n",
            "1. vomiting (Score: 0.5881)\n",
            "2. fatigue (Score: 0.5847)\n",
            "3. high_fever (Score: 0.5243)\n",
            "4. loss_of_appetite (Score: 0.5195)\n",
            "5. nausea (Score: 0.5177)\n",
            "6. headache (Score: 0.5040)\n",
            "7. abdominal_pain (Score: 0.4718)\n",
            "8. yellowing_of_eyes (Score: 0.4419)\n",
            "9. yellowish_skin (Score: 0.4285)\n",
            "10. chills (Score: 0.4038)\n",
            "11. malaise (Score: 0.3955)\n",
            "12. chest_pain (Score: 0.3895)\n",
            "13. skin_rash (Score: 0.3891)\n",
            "14. sweating (Score: 0.3789)\n",
            "15. joint_pain (Score: 0.3734)\n",
            "16. itching (Score: 0.3694)\n",
            "17. diarrhoea (Score: 0.3362)\n",
            "18. dark_urine (Score: 0.3318)\n",
            "19. cough (Score: 0.3190)\n",
            "20. irritability (Score: 0.3188)\n",
            "21. muscle_pain (Score: 0.3091)\n",
            "22. excessive_hunger (Score: 0.3017)\n",
            "23. weight_loss (Score: 0.2956)\n",
            "24. lethargy (Score: 0.2915)\n",
            "25. breathlessness (Score: 0.2888)\n",
            "26. phlegm (Score: 0.2579)\n",
            "27. swelled_lymph_nodes (Score: 0.2528)\n",
            "28. loss_of_balance (Score: 0.2504)\n",
            "29. mild_fever (Score: 0.2449)\n",
            "30. dizziness (Score: 0.2406)\n",
            "\n",
            "=== Handling Class Imbalance ===\n",
            "Applying combined sampling approach...\n",
            "Applying SMOTE for final balancing...\n",
            "Shape before resampling: (4961, 30)\n",
            "Shape after resampling: (4961, 30)\n",
            "\n",
            "=== Splitting Data into Train and Validation Sets ===\n",
            "\n",
            "=== Training and Evaluating Models ===\n",
            "Top Models: [('KNN', {'accuracy': 0.9073825503355705, 'precision': 0.9037208076854035, 'recall': 0.9073825503355705, 'f1': 0.893201801937848, 'auc': np.float64(0.991005131417221), 'train_time': 0.0040853023529052734, 'inference_time': 0.28498148918151855, 'y_pred': array([13, 13, 20, 25,  8, 20, 23, 33, 13, 29,  1, 35,  7, 12, 29, 40, 15,\n",
            "       39,  9, 10, 21, 34, 35, 12, 12, 40,  0, 17,  7, 19, 16, 17, 24, 12,\n",
            "        7,  6, 36,  7,  8, 37, 33,  8, 26, 10,  9, 26, 13, 12, 34, 33, 13,\n",
            "        3, 25, 39,  0,  1,  0, 20, 39, 21, 12, 24,  6, 26, 27,  2, 13,  5,\n",
            "       10,  0,  3, 11,  9, 40, 33, 23, 30, 39,  9, 20, 13, 27, 21, 36,  5,\n",
            "       15, 11, 23, 21, 37, 22, 16,  5,  0,  2, 34, 15, 25, 16, 27, 32, 37,\n",
            "        8, 20, 18, 32,  1, 34, 18,  9, 20, 25,  5,  3, 32, 13, 13,  1,  0,\n",
            "       12,  6, 15, 12,  1, 12,  8, 23, 12,  3, 25,  6, 17, 10, 31, 40, 33,\n",
            "       31, 13, 35,  6, 16, 25, 40, 12, 32, 24, 33, 31, 16, 23, 22,  3, 20,\n",
            "       29, 12,  1, 16,  9,  1, 39, 12, 12, 21, 11, 14,  7,  1, 18, 28,  5,\n",
            "       12, 18, 27, 36, 13, 40, 10,  1,  9,  3, 40,  1, 21, 12,  1,  3,  6,\n",
            "       37,  5, 15, 15, 30,  7, 23, 36, 28, 40,  5, 22, 26, 13, 13, 32, 25,\n",
            "       31, 36, 26, 12, 12, 12, 12,  5, 19, 22, 35,  6, 36, 24, 12, 19, 28,\n",
            "       21, 34, 16, 12, 21,  1, 35,  0, 12, 36, 18, 30, 19, 30, 19,  5, 39,\n",
            "       31, 36, 40, 13, 34, 22, 20, 10, 32, 15, 35, 25, 24, 35,  0, 25, 13,\n",
            "       23,  9,  0, 24,  9,  3, 15, 33,  3,  0, 30, 36, 15, 12, 34, 31, 11,\n",
            "        2, 22, 29,  6, 37, 12, 30, 16, 39,  1, 17,  3,  1, 28, 40, 27, 12,\n",
            "       31, 36, 17,  7, 26, 20, 23, 40, 17, 29, 28, 29,  3, 11, 12, 37, 30,\n",
            "       19, 35,  2, 14,  0, 13,  6, 31, 11, 26, 23,  9, 29, 18, 23,  8, 21,\n",
            "       37,  9,  2, 12, 28, 34,  6, 21, 25, 28, 16, 12, 35,  7, 25,  6, 39,\n",
            "       22, 26, 15, 19, 27, 10, 22, 15,  2, 34, 40, 26, 40, 31, 32, 23, 12,\n",
            "       32, 40, 40, 18, 10,  1, 23, 11, 20, 39, 23, 19,  1, 22, 33, 29, 15,\n",
            "       28, 15, 34, 22, 15, 31, 22, 39,  3,  8, 34, 13, 39, 32,  3, 37, 16,\n",
            "       34, 33,  8, 26, 12, 19, 12, 29,  5, 20, 12, 12, 21,  3,  2, 27, 34,\n",
            "       34, 30, 12,  6, 37, 27, 30, 31, 12, 10, 37, 32,  1, 13, 12, 21, 10,\n",
            "       13, 25, 33, 39, 32, 11, 28, 10, 37, 23,  8, 31, 28, 15, 30, 16, 30,\n",
            "       37,  9, 13, 35, 23, 35, 24,  1, 16, 17, 30,  5, 12, 14, 26, 13, 19,\n",
            "        9, 26,  2, 25, 19, 28,  6, 30, 12, 19,  1, 23, 21, 17,  7, 33, 13,\n",
            "       12, 10,  8, 36, 20,  2, 25, 11, 19, 24, 20, 31, 18, 28, 12,  6, 10,\n",
            "       11, 24, 29, 18, 12, 18, 35, 16, 30, 12, 40,  9,  8, 33, 25, 10,  2,\n",
            "       26, 33, 20, 17,  8, 21, 20, 22, 15,  7,  5, 36, 11, 39,  3, 32, 15,\n",
            "       25, 21, 32, 37, 22, 30,  7, 37,  8, 36,  3, 13, 36, 25, 26, 36, 27,\n",
            "        0, 39, 28, 31, 27, 24, 22, 26, 25,  2, 18, 18, 24, 26,  7,  5,  0,\n",
            "       29, 10,  7,  8, 32,  9, 31, 17, 32, 19, 17, 29, 31, 28, 16, 32, 12,\n",
            "       39, 22, 23,  0,  1, 10, 29, 12, 17, 28, 19, 29, 35, 24, 35, 34, 19,\n",
            "       12, 18, 12, 32, 29, 24, 12, 24, 24,  1, 12, 18,  0, 12, 18,  5, 33,\n",
            "       11, 12, 29, 17, 29, 37,  2,  7,  7, 39, 31, 16, 13, 11, 14, 16, 12,\n",
            "       17, 27, 39, 32, 17, 30, 11, 40, 19, 15, 26, 37,  1, 12,  9, 17, 24,\n",
            "       12,  5,  2, 28, 37,  8,  7,  2, 36, 22, 11, 35,  6, 35, 30,  1, 12,\n",
            "        6, 13,  1,  2, 40,  8,  5, 18,  8, 16,  2, 18, 20, 28, 10,  2, 24,\n",
            "       12, 17, 35,  7, 31, 33, 27, 34, 21, 22, 12,  5, 21, 36, 11, 17, 13,\n",
            "       10, 12, 12,  8,  6, 23, 13, 34, 28, 12, 21,  5, 33, 21, 37, 32, 12,\n",
            "       27, 18, 24, 33, 33, 33,  9, 30,  9,  1, 20, 29, 11,  7, 28,  1,  6,\n",
            "       26,  1, 34, 31, 20, 19,  1, 22,  7, 36, 20, 13, 11, 18]), 'y_prob': array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]]), 'model': KNeighborsClassifier(metric='hamming', weights='distance')}), ('Gradient Boosting', {'accuracy': 0.9046979865771813, 'precision': 0.8835146715396699, 'recall': 0.9046979865771813, 'f1': 0.8860865407764824, 'auc': np.float64(0.9963913243247133), 'train_time': 49.140341997146606, 'inference_time': 0.4234945774078369, 'y_pred': array([13, 13, 20, 25,  8, 20, 23, 33, 13, 29,  1, 35,  7,  4, 29, 40, 15,\n",
            "       39,  9, 10, 21, 34, 35,  4,  4, 40,  0, 17,  7, 19, 16, 17, 24,  4,\n",
            "        7,  6, 36,  7,  8, 37, 33,  8, 26, 10,  9, 26, 13,  4, 34, 33, 13,\n",
            "        3, 25, 39,  0,  1,  0, 20, 39, 21,  4, 24,  6, 26, 27,  2, 13,  5,\n",
            "       10,  0,  3, 11,  9, 40, 33, 23, 30, 39,  9, 20, 13, 27, 21, 36,  5,\n",
            "       15, 11, 23, 21, 37, 22, 16,  5,  0,  2, 34, 15, 25, 16, 27, 32, 37,\n",
            "        8, 20, 18, 32,  1, 34, 18,  9, 20, 25,  5,  3, 32, 13, 13,  1,  0,\n",
            "        4,  6, 15,  4,  1,  4,  8, 23,  4,  3, 25,  6, 17, 10, 31, 40, 33,\n",
            "       31, 13, 35,  6, 16, 25, 40,  4, 32, 24, 33, 31, 16, 23, 22,  3, 20,\n",
            "       29,  4,  1, 16,  9,  1, 39,  4,  4, 21, 11, 13,  7,  1, 18, 28,  5,\n",
            "        4, 18, 27, 36, 13, 40, 10,  1,  9,  3, 40,  1, 21,  4,  1,  3,  6,\n",
            "       37,  5, 15, 15, 30,  7, 23, 36, 28, 40,  5, 22, 26, 13, 13, 32, 25,\n",
            "       31, 36, 26,  4,  4,  4,  4,  5, 19, 22, 35,  6, 36, 24,  4, 19, 28,\n",
            "       21, 34, 16,  4, 21,  1, 35,  0,  4, 36, 18, 30, 19, 30, 19,  5, 39,\n",
            "       31, 36, 40, 13, 34, 22, 20, 10, 32, 15, 35, 25, 24, 35,  0, 25, 13,\n",
            "       23,  9,  0, 24,  9,  3, 15, 33,  3,  0, 30, 36, 15,  4, 34, 31, 11,\n",
            "        2, 22, 29,  6, 37,  4, 30, 16, 39,  1, 17,  3,  1, 28, 40, 27,  4,\n",
            "       31, 36, 17,  7, 26, 20, 23, 40, 17, 29, 28, 29,  3, 11,  4, 37, 30,\n",
            "       19, 35,  2, 13,  0, 13,  6, 31, 11, 26, 23,  9, 29, 18, 23,  8, 21,\n",
            "       37,  9,  2,  4, 28, 34,  6, 21, 25, 28, 16,  4, 35,  7, 25,  6, 39,\n",
            "       22, 26, 15, 19, 27, 10, 22, 15,  2, 34, 40, 26, 40, 31, 32, 23,  4,\n",
            "       32, 40, 40, 18, 10,  1, 23, 11, 20, 39, 23, 19,  1, 22, 33, 29, 15,\n",
            "       28, 15, 34, 22, 15, 31, 22, 39,  3,  8, 34, 13, 39, 32,  3, 37, 16,\n",
            "       34, 33,  8, 26,  4, 19,  4, 29,  5, 20,  4,  4, 21,  3,  2, 27, 34,\n",
            "       34, 30,  4,  6, 37, 27, 30, 31,  4, 10, 37, 32,  1, 13,  4, 21, 10,\n",
            "       13, 25, 33, 39, 32, 11, 28, 10, 37, 23,  8, 31, 28, 15, 30, 16, 30,\n",
            "       37,  9, 13, 35, 23, 35, 24,  1, 16, 17, 30,  5,  4, 13, 26, 13, 19,\n",
            "        9, 26,  2, 25, 19, 28,  6, 30,  4, 19,  1, 23, 21, 17,  7, 33, 13,\n",
            "        4, 10,  8, 36, 20,  2, 25, 11, 19, 24, 20, 31, 18, 28,  4,  6, 10,\n",
            "       11, 24, 29, 18,  4, 18, 35, 16, 30,  4, 40,  9,  8, 33, 25, 10,  2,\n",
            "       26, 33, 20, 17,  8, 21, 20, 22, 15,  7,  5, 36, 11, 39,  3, 32, 15,\n",
            "       25, 21, 32, 37, 22, 30,  7, 37,  8, 36,  3, 13, 36, 25, 26, 36, 27,\n",
            "        0, 39, 28, 31, 27, 24, 22, 26, 25,  2, 18, 18, 24, 26,  7,  5,  0,\n",
            "       29, 10,  7,  8, 32,  9, 31, 17, 32, 19, 17, 29, 31, 28, 16, 32,  4,\n",
            "       39, 22, 23,  0,  1, 10, 29,  4, 17, 28, 19, 29, 35, 24, 35, 34, 19,\n",
            "        4, 18,  4, 32, 29, 24,  4, 24, 24,  1,  4, 18,  0,  4, 18,  5, 33,\n",
            "       11,  4, 29, 17, 29, 37,  2,  7,  7, 39, 31, 16, 13, 11, 13, 16,  4,\n",
            "       17, 27, 39, 32, 17, 30, 11, 40, 19, 15, 26, 37,  1,  4,  9, 17, 24,\n",
            "        4,  5,  2, 28, 37,  8,  7,  2, 36, 22, 11, 35,  6, 35, 30,  1,  4,\n",
            "        6, 13,  1,  2, 40,  8,  5, 18,  8, 16,  2, 18, 20, 28, 10,  2, 24,\n",
            "        4, 17, 35,  7, 31, 33, 27, 34, 21, 22,  4,  5, 21, 36, 11, 17, 13,\n",
            "       10,  4,  4,  8,  6, 23, 13, 34, 28,  4, 21,  5, 33, 21, 37, 32,  4,\n",
            "       27, 18, 24, 33, 33, 33,  9, 30,  9,  1, 20, 29, 11,  7, 28,  1,  6,\n",
            "       26,  1, 34, 31, 20, 19,  1, 22,  7, 36, 20, 13, 11, 18]), 'y_prob': array([[1.62364424e-06, 1.35804501e-06, 9.94981167e-07, ...,\n",
            "        9.35697114e-07, 1.14698241e-06, 8.99201397e-07],\n",
            "       [1.62364424e-06, 1.35804501e-06, 9.94981167e-07, ...,\n",
            "        9.35697114e-07, 1.14698241e-06, 8.99201397e-07],\n",
            "       [2.02660975e-10, 3.91339123e-10, 1.79174511e-10, ...,\n",
            "        3.10004499e-10, 4.97266328e-07, 1.79032478e-10],\n",
            "       ...,\n",
            "       [1.62364424e-06, 1.35804501e-06, 9.94981167e-07, ...,\n",
            "        9.35697114e-07, 1.14698241e-06, 8.99201397e-07],\n",
            "       [1.52291347e-10, 2.78744615e-10, 1.23265903e-10, ...,\n",
            "        1.93441780e-10, 4.05175877e-09, 1.23432769e-10],\n",
            "       [1.28343505e-10, 1.23309324e-10, 9.70471387e-10, ...,\n",
            "        1.22204959e-10, 1.30033473e-10, 3.39020377e-09]]), 'model': GradientBoostingClassifier(learning_rate=0.05, max_depth=5,\n",
            "                           min_samples_split=10, n_estimators=200,\n",
            "                           random_state=42, subsample=0.8)}), ('Bernoulli NB', {'accuracy': 0.9046979865771813, 'precision': 0.8835146715396699, 'recall': 0.9046979865771813, 'f1': 0.8860865407764824, 'auc': np.float64(0.9964513499463142), 'train_time': 0.01135563850402832, 'inference_time': 0.007741212844848633, 'y_pred': array([13, 13, 20, 25,  8, 20, 23, 33, 13, 29,  1, 35,  7,  4, 29, 40, 15,\n",
            "       39,  9, 10, 21, 34, 35,  4,  4, 40,  0, 17,  7, 19, 16, 17, 24,  4,\n",
            "        7,  6, 36,  7,  8, 37, 33,  8, 26, 10,  9, 26, 13,  4, 34, 33, 13,\n",
            "        3, 25, 39,  0,  1,  0, 20, 39, 21,  4, 24,  6, 26, 27,  2, 13,  5,\n",
            "       10,  0,  3, 11,  9, 40, 33, 23, 30, 39,  9, 20, 13, 27, 21, 36,  5,\n",
            "       15, 11, 23, 21, 37, 22, 16,  5,  0,  2, 34, 15, 25, 16, 27, 32, 37,\n",
            "        8, 20, 18, 32,  1, 34, 18,  9, 20, 25,  5,  3, 32, 13, 13,  1,  0,\n",
            "        4,  6, 15,  4,  1,  4,  8, 23,  4,  3, 25,  6, 17, 10, 31, 40, 33,\n",
            "       31, 13, 35,  6, 16, 25, 40,  4, 32, 24, 33, 31, 16, 23, 22,  3, 20,\n",
            "       29,  4,  1, 16,  9,  1, 39,  4,  4, 21, 11, 13,  7,  1, 18, 28,  5,\n",
            "        4, 18, 27, 36, 13, 40, 10,  1,  9,  3, 40,  1, 21,  4,  1,  3,  6,\n",
            "       37,  5, 15, 15, 30,  7, 23, 36, 28, 40,  5, 22, 26, 13, 13, 32, 25,\n",
            "       31, 36, 26,  4,  4,  4,  4,  5, 19, 22, 35,  6, 36, 24,  4, 19, 28,\n",
            "       21, 34, 16,  4, 21,  1, 35,  0,  4, 36, 18, 30, 19, 30, 19,  5, 39,\n",
            "       31, 36, 40, 13, 34, 22, 20, 10, 32, 15, 35, 25, 24, 35,  0, 25, 13,\n",
            "       23,  9,  0, 24,  9,  3, 15, 33,  3,  0, 30, 36, 15,  4, 34, 31, 11,\n",
            "        2, 22, 29,  6, 37,  4, 30, 16, 39,  1, 17,  3,  1, 28, 40, 27,  4,\n",
            "       31, 36, 17,  7, 26, 20, 23, 40, 17, 29, 28, 29,  3, 11,  4, 37, 30,\n",
            "       19, 35,  2, 13,  0, 13,  6, 31, 11, 26, 23,  9, 29, 18, 23,  8, 21,\n",
            "       37,  9,  2,  4, 28, 34,  6, 21, 25, 28, 16,  4, 35,  7, 25,  6, 39,\n",
            "       22, 26, 15, 19, 27, 10, 22, 15,  2, 34, 40, 26, 40, 31, 32, 23,  4,\n",
            "       32, 40, 40, 18, 10,  1, 23, 11, 20, 39, 23, 19,  1, 22, 33, 29, 15,\n",
            "       28, 15, 34, 22, 15, 31, 22, 39,  3,  8, 34, 13, 39, 32,  3, 37, 16,\n",
            "       34, 33,  8, 26,  4, 19,  4, 29,  5, 20,  4,  4, 21,  3,  2, 27, 34,\n",
            "       34, 30,  4,  6, 37, 27, 30, 31,  4, 10, 37, 32,  1, 13,  4, 21, 10,\n",
            "       13, 25, 33, 39, 32, 11, 28, 10, 37, 23,  8, 31, 28, 15, 30, 16, 30,\n",
            "       37,  9, 13, 35, 23, 35, 24,  1, 16, 17, 30,  5,  4, 13, 26, 13, 19,\n",
            "        9, 26,  2, 25, 19, 28,  6, 30,  4, 19,  1, 23, 21, 17,  7, 33, 13,\n",
            "        4, 10,  8, 36, 20,  2, 25, 11, 19, 24, 20, 31, 18, 28,  4,  6, 10,\n",
            "       11, 24, 29, 18,  4, 18, 35, 16, 30,  4, 40,  9,  8, 33, 25, 10,  2,\n",
            "       26, 33, 20, 17,  8, 21, 20, 22, 15,  7,  5, 36, 11, 39,  3, 32, 15,\n",
            "       25, 21, 32, 37, 22, 30,  7, 37,  8, 36,  3, 13, 36, 25, 26, 36, 27,\n",
            "        0, 39, 28, 31, 27, 24, 22, 26, 25,  2, 18, 18, 24, 26,  7,  5,  0,\n",
            "       29, 10,  7,  8, 32,  9, 31, 17, 32, 19, 17, 29, 31, 28, 16, 32,  4,\n",
            "       39, 22, 23,  0,  1, 10, 29,  4, 17, 28, 19, 29, 35, 24, 35, 34, 19,\n",
            "        4, 18,  4, 32, 29, 24,  4, 24, 24,  1,  4, 18,  0,  4, 18,  5, 33,\n",
            "       11,  4, 29, 17, 29, 37,  2,  7,  7, 39, 31, 16, 13, 11, 13, 16,  4,\n",
            "       17, 27, 39, 32, 17, 30, 11, 40, 19, 15, 26, 37,  1,  4,  9, 17, 24,\n",
            "        4,  5,  2, 28, 37,  8,  7,  2, 36, 22, 11, 35,  6, 35, 30,  1,  4,\n",
            "        6, 13,  1,  2, 40,  8,  5, 18,  8, 16,  2, 18, 20, 28, 10,  2, 24,\n",
            "        4, 17, 35,  7, 31, 33, 27, 34, 21, 22,  4,  5, 21, 36, 11, 17, 13,\n",
            "       10,  4,  4,  8,  6, 23, 13, 34, 28,  4, 21,  5, 33, 21, 37, 32,  4,\n",
            "       27, 18, 24, 33, 33, 33,  9, 30,  9,  1, 20, 29, 11,  7, 28,  1,  6,\n",
            "       26,  1, 34, 31, 20, 19,  1, 22,  7, 36, 20, 13, 11, 18]), 'y_prob': array([[2.09935257e-06, 5.34915036e-03, 1.01900897e-08, ...,\n",
            "        5.49552593e-05, 3.14902886e-06, 8.23045706e-10],\n",
            "       [2.09935257e-06, 5.34915036e-03, 1.01900897e-08, ...,\n",
            "        5.49552593e-05, 3.14902886e-06, 8.23045706e-10],\n",
            "       [1.11433090e-08, 1.95007907e-08, 9.28162636e-08, ...,\n",
            "        2.97392685e-07, 2.86828773e-05, 4.36870525e-12],\n",
            "       ...,\n",
            "       [2.09935257e-06, 5.34915036e-03, 1.01900897e-08, ...,\n",
            "        5.49552593e-05, 3.14902886e-06, 8.23045706e-10],\n",
            "       [3.92424077e-10, 6.86742134e-10, 1.90479512e-12, ...,\n",
            "        1.04730157e-08, 1.01009957e-06, 1.53848837e-13],\n",
            "       [3.65395698e-24, 6.39442472e-24, 9.21717956e-17, ...,\n",
            "        1.04340362e-22, 5.48093547e-24, 3.57915627e-21]]), 'model': BernoulliNB()}), ('CatBoost', {'accuracy': 0.9046979865771813, 'precision': 0.8835146715396699, 'recall': 0.9046979865771813, 'f1': 0.8860865407764824, 'auc': np.float64(0.996305587566383), 'train_time': 16.505988359451294, 'inference_time': 0.011922359466552734, 'y_pred': array([[13],\n",
            "       [13],\n",
            "       [20],\n",
            "       [25],\n",
            "       [ 8],\n",
            "       [20],\n",
            "       [23],\n",
            "       [33],\n",
            "       [13],\n",
            "       [29],\n",
            "       [ 1],\n",
            "       [35],\n",
            "       [ 7],\n",
            "       [ 4],\n",
            "       [29],\n",
            "       [40],\n",
            "       [15],\n",
            "       [39],\n",
            "       [ 9],\n",
            "       [10],\n",
            "       [21],\n",
            "       [34],\n",
            "       [35],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [40],\n",
            "       [ 0],\n",
            "       [17],\n",
            "       [ 7],\n",
            "       [19],\n",
            "       [16],\n",
            "       [17],\n",
            "       [24],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [ 6],\n",
            "       [36],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [37],\n",
            "       [33],\n",
            "       [ 8],\n",
            "       [26],\n",
            "       [10],\n",
            "       [ 9],\n",
            "       [26],\n",
            "       [13],\n",
            "       [ 4],\n",
            "       [34],\n",
            "       [33],\n",
            "       [13],\n",
            "       [ 3],\n",
            "       [25],\n",
            "       [39],\n",
            "       [ 0],\n",
            "       [ 1],\n",
            "       [ 0],\n",
            "       [20],\n",
            "       [39],\n",
            "       [21],\n",
            "       [ 4],\n",
            "       [24],\n",
            "       [ 6],\n",
            "       [26],\n",
            "       [27],\n",
            "       [ 2],\n",
            "       [13],\n",
            "       [ 5],\n",
            "       [10],\n",
            "       [ 0],\n",
            "       [ 3],\n",
            "       [11],\n",
            "       [ 9],\n",
            "       [40],\n",
            "       [33],\n",
            "       [23],\n",
            "       [30],\n",
            "       [39],\n",
            "       [ 9],\n",
            "       [20],\n",
            "       [13],\n",
            "       [27],\n",
            "       [21],\n",
            "       [36],\n",
            "       [ 5],\n",
            "       [15],\n",
            "       [11],\n",
            "       [23],\n",
            "       [21],\n",
            "       [37],\n",
            "       [22],\n",
            "       [16],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [ 2],\n",
            "       [34],\n",
            "       [15],\n",
            "       [25],\n",
            "       [16],\n",
            "       [27],\n",
            "       [32],\n",
            "       [37],\n",
            "       [ 8],\n",
            "       [20],\n",
            "       [18],\n",
            "       [32],\n",
            "       [ 1],\n",
            "       [34],\n",
            "       [18],\n",
            "       [ 9],\n",
            "       [20],\n",
            "       [25],\n",
            "       [ 5],\n",
            "       [ 3],\n",
            "       [32],\n",
            "       [13],\n",
            "       [13],\n",
            "       [ 1],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [ 6],\n",
            "       [15],\n",
            "       [ 4],\n",
            "       [ 1],\n",
            "       [ 4],\n",
            "       [ 8],\n",
            "       [23],\n",
            "       [ 4],\n",
            "       [ 3],\n",
            "       [25],\n",
            "       [ 6],\n",
            "       [17],\n",
            "       [10],\n",
            "       [31],\n",
            "       [40],\n",
            "       [33],\n",
            "       [31],\n",
            "       [13],\n",
            "       [35],\n",
            "       [ 6],\n",
            "       [16],\n",
            "       [25],\n",
            "       [40],\n",
            "       [ 4],\n",
            "       [32],\n",
            "       [24],\n",
            "       [33],\n",
            "       [31],\n",
            "       [16],\n",
            "       [23],\n",
            "       [22],\n",
            "       [ 3],\n",
            "       [20],\n",
            "       [29],\n",
            "       [ 4],\n",
            "       [ 1],\n",
            "       [16],\n",
            "       [ 9],\n",
            "       [ 1],\n",
            "       [39],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [11],\n",
            "       [13],\n",
            "       [ 7],\n",
            "       [ 1],\n",
            "       [18],\n",
            "       [28],\n",
            "       [ 5],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [27],\n",
            "       [36],\n",
            "       [13],\n",
            "       [40],\n",
            "       [10],\n",
            "       [ 1],\n",
            "       [ 9],\n",
            "       [ 3],\n",
            "       [40],\n",
            "       [ 1],\n",
            "       [21],\n",
            "       [ 4],\n",
            "       [ 1],\n",
            "       [ 3],\n",
            "       [ 6],\n",
            "       [37],\n",
            "       [ 5],\n",
            "       [15],\n",
            "       [15],\n",
            "       [30],\n",
            "       [ 7],\n",
            "       [23],\n",
            "       [36],\n",
            "       [28],\n",
            "       [40],\n",
            "       [ 5],\n",
            "       [22],\n",
            "       [26],\n",
            "       [13],\n",
            "       [13],\n",
            "       [32],\n",
            "       [25],\n",
            "       [31],\n",
            "       [36],\n",
            "       [26],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 5],\n",
            "       [19],\n",
            "       [22],\n",
            "       [35],\n",
            "       [ 6],\n",
            "       [36],\n",
            "       [24],\n",
            "       [ 4],\n",
            "       [19],\n",
            "       [28],\n",
            "       [21],\n",
            "       [34],\n",
            "       [16],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [ 1],\n",
            "       [35],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [36],\n",
            "       [18],\n",
            "       [30],\n",
            "       [19],\n",
            "       [30],\n",
            "       [19],\n",
            "       [ 5],\n",
            "       [39],\n",
            "       [31],\n",
            "       [36],\n",
            "       [40],\n",
            "       [13],\n",
            "       [34],\n",
            "       [22],\n",
            "       [20],\n",
            "       [10],\n",
            "       [32],\n",
            "       [15],\n",
            "       [35],\n",
            "       [25],\n",
            "       [24],\n",
            "       [35],\n",
            "       [ 0],\n",
            "       [25],\n",
            "       [13],\n",
            "       [23],\n",
            "       [ 9],\n",
            "       [ 0],\n",
            "       [24],\n",
            "       [ 9],\n",
            "       [ 3],\n",
            "       [15],\n",
            "       [33],\n",
            "       [ 3],\n",
            "       [ 0],\n",
            "       [30],\n",
            "       [36],\n",
            "       [15],\n",
            "       [ 4],\n",
            "       [34],\n",
            "       [31],\n",
            "       [11],\n",
            "       [ 2],\n",
            "       [22],\n",
            "       [29],\n",
            "       [ 6],\n",
            "       [37],\n",
            "       [ 4],\n",
            "       [30],\n",
            "       [16],\n",
            "       [39],\n",
            "       [ 1],\n",
            "       [17],\n",
            "       [ 3],\n",
            "       [ 1],\n",
            "       [28],\n",
            "       [40],\n",
            "       [27],\n",
            "       [ 4],\n",
            "       [31],\n",
            "       [36],\n",
            "       [17],\n",
            "       [ 7],\n",
            "       [26],\n",
            "       [20],\n",
            "       [23],\n",
            "       [40],\n",
            "       [17],\n",
            "       [29],\n",
            "       [28],\n",
            "       [29],\n",
            "       [ 3],\n",
            "       [11],\n",
            "       [ 4],\n",
            "       [37],\n",
            "       [30],\n",
            "       [19],\n",
            "       [35],\n",
            "       [ 2],\n",
            "       [13],\n",
            "       [ 0],\n",
            "       [13],\n",
            "       [ 6],\n",
            "       [31],\n",
            "       [11],\n",
            "       [26],\n",
            "       [23],\n",
            "       [ 9],\n",
            "       [29],\n",
            "       [18],\n",
            "       [23],\n",
            "       [ 8],\n",
            "       [21],\n",
            "       [37],\n",
            "       [ 9],\n",
            "       [ 2],\n",
            "       [ 4],\n",
            "       [28],\n",
            "       [34],\n",
            "       [ 6],\n",
            "       [21],\n",
            "       [25],\n",
            "       [28],\n",
            "       [16],\n",
            "       [ 4],\n",
            "       [35],\n",
            "       [ 7],\n",
            "       [25],\n",
            "       [ 6],\n",
            "       [39],\n",
            "       [22],\n",
            "       [26],\n",
            "       [15],\n",
            "       [19],\n",
            "       [27],\n",
            "       [10],\n",
            "       [22],\n",
            "       [15],\n",
            "       [ 2],\n",
            "       [34],\n",
            "       [40],\n",
            "       [26],\n",
            "       [40],\n",
            "       [31],\n",
            "       [32],\n",
            "       [23],\n",
            "       [ 4],\n",
            "       [32],\n",
            "       [40],\n",
            "       [40],\n",
            "       [18],\n",
            "       [10],\n",
            "       [ 1],\n",
            "       [23],\n",
            "       [11],\n",
            "       [20],\n",
            "       [39],\n",
            "       [23],\n",
            "       [19],\n",
            "       [ 1],\n",
            "       [22],\n",
            "       [33],\n",
            "       [29],\n",
            "       [15],\n",
            "       [28],\n",
            "       [15],\n",
            "       [34],\n",
            "       [22],\n",
            "       [15],\n",
            "       [31],\n",
            "       [22],\n",
            "       [39],\n",
            "       [ 3],\n",
            "       [ 8],\n",
            "       [34],\n",
            "       [13],\n",
            "       [39],\n",
            "       [32],\n",
            "       [ 3],\n",
            "       [37],\n",
            "       [16],\n",
            "       [34],\n",
            "       [33],\n",
            "       [ 8],\n",
            "       [26],\n",
            "       [ 4],\n",
            "       [19],\n",
            "       [ 4],\n",
            "       [29],\n",
            "       [ 5],\n",
            "       [20],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [ 3],\n",
            "       [ 2],\n",
            "       [27],\n",
            "       [34],\n",
            "       [34],\n",
            "       [30],\n",
            "       [ 4],\n",
            "       [ 6],\n",
            "       [37],\n",
            "       [27],\n",
            "       [30],\n",
            "       [31],\n",
            "       [ 4],\n",
            "       [10],\n",
            "       [37],\n",
            "       [32],\n",
            "       [ 1],\n",
            "       [13],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [10],\n",
            "       [13],\n",
            "       [25],\n",
            "       [33],\n",
            "       [39],\n",
            "       [32],\n",
            "       [11],\n",
            "       [28],\n",
            "       [10],\n",
            "       [37],\n",
            "       [23],\n",
            "       [ 8],\n",
            "       [31],\n",
            "       [28],\n",
            "       [15],\n",
            "       [30],\n",
            "       [16],\n",
            "       [30],\n",
            "       [37],\n",
            "       [ 9],\n",
            "       [13],\n",
            "       [35],\n",
            "       [23],\n",
            "       [35],\n",
            "       [24],\n",
            "       [ 1],\n",
            "       [16],\n",
            "       [17],\n",
            "       [30],\n",
            "       [ 5],\n",
            "       [ 4],\n",
            "       [13],\n",
            "       [26],\n",
            "       [13],\n",
            "       [19],\n",
            "       [ 9],\n",
            "       [26],\n",
            "       [ 2],\n",
            "       [25],\n",
            "       [19],\n",
            "       [28],\n",
            "       [ 6],\n",
            "       [30],\n",
            "       [ 4],\n",
            "       [19],\n",
            "       [ 1],\n",
            "       [23],\n",
            "       [21],\n",
            "       [17],\n",
            "       [ 7],\n",
            "       [33],\n",
            "       [13],\n",
            "       [ 4],\n",
            "       [10],\n",
            "       [ 8],\n",
            "       [36],\n",
            "       [20],\n",
            "       [ 2],\n",
            "       [25],\n",
            "       [11],\n",
            "       [19],\n",
            "       [24],\n",
            "       [20],\n",
            "       [31],\n",
            "       [18],\n",
            "       [28],\n",
            "       [ 4],\n",
            "       [ 6],\n",
            "       [10],\n",
            "       [11],\n",
            "       [24],\n",
            "       [29],\n",
            "       [18],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [35],\n",
            "       [16],\n",
            "       [30],\n",
            "       [ 4],\n",
            "       [40],\n",
            "       [ 9],\n",
            "       [ 8],\n",
            "       [33],\n",
            "       [25],\n",
            "       [10],\n",
            "       [ 2],\n",
            "       [26],\n",
            "       [33],\n",
            "       [20],\n",
            "       [17],\n",
            "       [ 8],\n",
            "       [21],\n",
            "       [20],\n",
            "       [22],\n",
            "       [15],\n",
            "       [ 7],\n",
            "       [ 5],\n",
            "       [36],\n",
            "       [11],\n",
            "       [39],\n",
            "       [ 3],\n",
            "       [32],\n",
            "       [15],\n",
            "       [25],\n",
            "       [21],\n",
            "       [32],\n",
            "       [37],\n",
            "       [22],\n",
            "       [30],\n",
            "       [ 7],\n",
            "       [37],\n",
            "       [ 8],\n",
            "       [36],\n",
            "       [ 3],\n",
            "       [13],\n",
            "       [36],\n",
            "       [25],\n",
            "       [26],\n",
            "       [36],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [39],\n",
            "       [28],\n",
            "       [31],\n",
            "       [27],\n",
            "       [24],\n",
            "       [22],\n",
            "       [26],\n",
            "       [25],\n",
            "       [ 2],\n",
            "       [18],\n",
            "       [18],\n",
            "       [24],\n",
            "       [26],\n",
            "       [ 7],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [29],\n",
            "       [10],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [32],\n",
            "       [ 9],\n",
            "       [31],\n",
            "       [17],\n",
            "       [32],\n",
            "       [19],\n",
            "       [17],\n",
            "       [29],\n",
            "       [31],\n",
            "       [28],\n",
            "       [16],\n",
            "       [32],\n",
            "       [ 4],\n",
            "       [39],\n",
            "       [22],\n",
            "       [23],\n",
            "       [ 0],\n",
            "       [ 1],\n",
            "       [10],\n",
            "       [29],\n",
            "       [ 4],\n",
            "       [17],\n",
            "       [28],\n",
            "       [19],\n",
            "       [29],\n",
            "       [35],\n",
            "       [24],\n",
            "       [35],\n",
            "       [34],\n",
            "       [19],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [ 4],\n",
            "       [32],\n",
            "       [29],\n",
            "       [24],\n",
            "       [ 4],\n",
            "       [24],\n",
            "       [24],\n",
            "       [ 1],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [ 5],\n",
            "       [33],\n",
            "       [11],\n",
            "       [ 4],\n",
            "       [29],\n",
            "       [17],\n",
            "       [29],\n",
            "       [37],\n",
            "       [ 2],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [39],\n",
            "       [31],\n",
            "       [16],\n",
            "       [13],\n",
            "       [11],\n",
            "       [13],\n",
            "       [16],\n",
            "       [ 4],\n",
            "       [17],\n",
            "       [27],\n",
            "       [39],\n",
            "       [32],\n",
            "       [17],\n",
            "       [30],\n",
            "       [11],\n",
            "       [40],\n",
            "       [19],\n",
            "       [15],\n",
            "       [26],\n",
            "       [37],\n",
            "       [ 1],\n",
            "       [ 4],\n",
            "       [ 9],\n",
            "       [17],\n",
            "       [24],\n",
            "       [ 4],\n",
            "       [ 5],\n",
            "       [ 2],\n",
            "       [28],\n",
            "       [37],\n",
            "       [ 8],\n",
            "       [ 7],\n",
            "       [ 2],\n",
            "       [36],\n",
            "       [22],\n",
            "       [11],\n",
            "       [35],\n",
            "       [ 6],\n",
            "       [35],\n",
            "       [30],\n",
            "       [ 1],\n",
            "       [ 4],\n",
            "       [ 6],\n",
            "       [13],\n",
            "       [ 1],\n",
            "       [ 2],\n",
            "       [40],\n",
            "       [ 8],\n",
            "       [ 5],\n",
            "       [18],\n",
            "       [ 8],\n",
            "       [16],\n",
            "       [ 2],\n",
            "       [18],\n",
            "       [20],\n",
            "       [28],\n",
            "       [10],\n",
            "       [ 2],\n",
            "       [24],\n",
            "       [ 4],\n",
            "       [17],\n",
            "       [35],\n",
            "       [ 7],\n",
            "       [31],\n",
            "       [33],\n",
            "       [27],\n",
            "       [34],\n",
            "       [21],\n",
            "       [22],\n",
            "       [ 4],\n",
            "       [ 5],\n",
            "       [21],\n",
            "       [36],\n",
            "       [11],\n",
            "       [17],\n",
            "       [13],\n",
            "       [10],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 8],\n",
            "       [ 6],\n",
            "       [23],\n",
            "       [13],\n",
            "       [34],\n",
            "       [28],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [ 5],\n",
            "       [33],\n",
            "       [21],\n",
            "       [37],\n",
            "       [32],\n",
            "       [ 4],\n",
            "       [27],\n",
            "       [18],\n",
            "       [24],\n",
            "       [33],\n",
            "       [33],\n",
            "       [33],\n",
            "       [ 9],\n",
            "       [30],\n",
            "       [ 9],\n",
            "       [ 1],\n",
            "       [20],\n",
            "       [29],\n",
            "       [11],\n",
            "       [ 7],\n",
            "       [28],\n",
            "       [ 1],\n",
            "       [ 6],\n",
            "       [26],\n",
            "       [ 1],\n",
            "       [34],\n",
            "       [31],\n",
            "       [20],\n",
            "       [19],\n",
            "       [ 1],\n",
            "       [22],\n",
            "       [ 7],\n",
            "       [36],\n",
            "       [20],\n",
            "       [13],\n",
            "       [11],\n",
            "       [18]]), 'y_prob': array([[9.64660443e-05, 7.10645591e-04, 3.50163344e-05, ...,\n",
            "        2.22148314e-04, 5.20132552e-05, 1.48700580e-05],\n",
            "       [9.64660443e-05, 7.10645591e-04, 3.50163344e-05, ...,\n",
            "        2.22148314e-04, 5.20132552e-05, 1.48700580e-05],\n",
            "       [3.31004756e-04, 4.88750339e-04, 7.04207679e-04, ...,\n",
            "        9.16039473e-04, 2.50126091e-02, 2.08762717e-04],\n",
            "       ...,\n",
            "       [9.64660443e-05, 7.10645591e-04, 3.50163344e-05, ...,\n",
            "        2.22148314e-04, 5.20132552e-05, 1.48700580e-05],\n",
            "       [2.38585445e-05, 2.13861605e-05, 8.43462625e-06, ...,\n",
            "        6.08970304e-05, 2.37139759e-03, 1.15957396e-05],\n",
            "       [1.34483196e-05, 1.66410317e-05, 6.25806028e-05, ...,\n",
            "        1.48955321e-05, 1.45681207e-05, 2.52192066e-05]]), 'model': <catboost.core.CatBoostClassifier object at 0x78ba53d23e90>}), ('Stacking Ensemble', {'accuracy': 0.9046979865771813, 'precision': 0.8835146715396699, 'recall': 0.9046979865771813, 'f1': 0.8860865407764824, 'auc': np.float64(0.9963875966395686), 'train_time': 60.521371603012085, 'inference_time': 0.380537748336792, 'y_pred': array([13, 13, 20, 25,  8, 20, 23, 33, 13, 29,  1, 35,  7,  4, 29, 40, 15,\n",
            "       39,  9, 10, 21, 34, 35,  4,  4, 40,  0, 17,  7, 19, 16, 17, 24,  4,\n",
            "        7,  6, 36,  7,  8, 37, 33,  8, 26, 10,  9, 26, 13,  4, 34, 33, 13,\n",
            "        3, 25, 39,  0,  1,  0, 20, 39, 21,  4, 24,  6, 26, 27,  2, 13,  5,\n",
            "       10,  0,  3, 11,  9, 40, 33, 23, 30, 39,  9, 20, 13, 27, 21, 36,  5,\n",
            "       15, 11, 23, 21, 37, 22, 16,  5,  0,  2, 34, 15, 25, 16, 27, 32, 37,\n",
            "        8, 20, 18, 32,  1, 34, 18,  9, 20, 25,  5,  3, 32, 13, 13,  1,  0,\n",
            "        4,  6, 15,  4,  1,  4,  8, 23,  4,  3, 25,  6, 17, 10, 31, 40, 33,\n",
            "       31, 13, 35,  6, 16, 25, 40,  4, 32, 24, 33, 31, 16, 23, 22,  3, 20,\n",
            "       29,  4,  1, 16,  9,  1, 39,  4,  4, 21, 11, 13,  7,  1, 18, 28,  5,\n",
            "        4, 18, 27, 36, 13, 40, 10,  1,  9,  3, 40,  1, 21,  4,  1,  3,  6,\n",
            "       37,  5, 15, 15, 30,  7, 23, 36, 28, 40,  5, 22, 26, 13, 13, 32, 25,\n",
            "       31, 36, 26,  4,  4,  4,  4,  5, 19, 22, 35,  6, 36, 24,  4, 19, 28,\n",
            "       21, 34, 16,  4, 21,  1, 35,  0,  4, 36, 18, 30, 19, 30, 19,  5, 39,\n",
            "       31, 36, 40, 13, 34, 22, 20, 10, 32, 15, 35, 25, 24, 35,  0, 25, 13,\n",
            "       23,  9,  0, 24,  9,  3, 15, 33,  3,  0, 30, 36, 15,  4, 34, 31, 11,\n",
            "        2, 22, 29,  6, 37,  4, 30, 16, 39,  1, 17,  3,  1, 28, 40, 27,  4,\n",
            "       31, 36, 17,  7, 26, 20, 23, 40, 17, 29, 28, 29,  3, 11,  4, 37, 30,\n",
            "       19, 35,  2, 13,  0, 13,  6, 31, 11, 26, 23,  9, 29, 18, 23,  8, 21,\n",
            "       37,  9,  2,  4, 28, 34,  6, 21, 25, 28, 16,  4, 35,  7, 25,  6, 39,\n",
            "       22, 26, 15, 19, 27, 10, 22, 15,  2, 34, 40, 26, 40, 31, 32, 23,  4,\n",
            "       32, 40, 40, 18, 10,  1, 23, 11, 20, 39, 23, 19,  1, 22, 33, 29, 15,\n",
            "       28, 15, 34, 22, 15, 31, 22, 39,  3,  8, 34, 13, 39, 32,  3, 37, 16,\n",
            "       34, 33,  8, 26,  4, 19,  4, 29,  5, 20,  4,  4, 21,  3,  2, 27, 34,\n",
            "       34, 30,  4,  6, 37, 27, 30, 31,  4, 10, 37, 32,  1, 13,  4, 21, 10,\n",
            "       13, 25, 33, 39, 32, 11, 28, 10, 37, 23,  8, 31, 28, 15, 30, 16, 30,\n",
            "       37,  9, 13, 35, 23, 35, 24,  1, 16, 17, 30,  5,  4, 13, 26, 13, 19,\n",
            "        9, 26,  2, 25, 19, 28,  6, 30,  4, 19,  1, 23, 21, 17,  7, 33, 13,\n",
            "        4, 10,  8, 36, 20,  2, 25, 11, 19, 24, 20, 31, 18, 28,  4,  6, 10,\n",
            "       11, 24, 29, 18,  4, 18, 35, 16, 30,  4, 40,  9,  8, 33, 25, 10,  2,\n",
            "       26, 33, 20, 17,  8, 21, 20, 22, 15,  7,  5, 36, 11, 39,  3, 32, 15,\n",
            "       25, 21, 32, 37, 22, 30,  7, 37,  8, 36,  3, 13, 36, 25, 26, 36, 27,\n",
            "        0, 39, 28, 31, 27, 24, 22, 26, 25,  2, 18, 18, 24, 26,  7,  5,  0,\n",
            "       29, 10,  7,  8, 32,  9, 31, 17, 32, 19, 17, 29, 31, 28, 16, 32,  4,\n",
            "       39, 22, 23,  0,  1, 10, 29,  4, 17, 28, 19, 29, 35, 24, 35, 34, 19,\n",
            "        4, 18,  4, 32, 29, 24,  4, 24, 24,  1,  4, 18,  0,  4, 18,  5, 33,\n",
            "       11,  4, 29, 17, 29, 37,  2,  7,  7, 39, 31, 16, 13, 11, 13, 16,  4,\n",
            "       17, 27, 39, 32, 17, 30, 11, 40, 19, 15, 26, 37,  1,  4,  9, 17, 24,\n",
            "        4,  5,  2, 28, 37,  8,  7,  2, 36, 22, 11, 35,  6, 35, 30,  1,  4,\n",
            "        6, 13,  1,  2, 40,  8,  5, 18,  8, 16,  2, 18, 20, 28, 10,  2, 24,\n",
            "        4, 17, 35,  7, 31, 33, 27, 34, 21, 22,  4,  5, 21, 36, 11, 17, 13,\n",
            "       10,  4,  4,  8,  6, 23, 13, 34, 28,  4, 21,  5, 33, 21, 37, 32,  4,\n",
            "       27, 18, 24, 33, 33, 33,  9, 30,  9,  1, 20, 29, 11,  7, 28,  1,  6,\n",
            "       26,  1, 34, 31, 20, 19,  1, 22,  7, 36, 20, 13, 11, 18]), 'y_prob': array([[3.07601505e-04, 1.99957492e-03, 1.67704755e-04, ...,\n",
            "        4.87423141e-04, 3.67292870e-04, 1.24215482e-04],\n",
            "       [3.07601505e-04, 1.99957492e-03, 1.67704755e-04, ...,\n",
            "        4.87423141e-04, 3.67292870e-04, 1.24215482e-04],\n",
            "       [7.92188907e-04, 1.17173253e-03, 7.18599172e-04, ...,\n",
            "        1.66475506e-03, 3.15996064e-03, 2.15311760e-04],\n",
            "       ...,\n",
            "       [3.07601505e-04, 1.99957492e-03, 1.67704755e-04, ...,\n",
            "        4.87423141e-04, 3.67292870e-04, 1.24215482e-04],\n",
            "       [1.86844673e-04, 2.58603147e-04, 8.92885372e-05, ...,\n",
            "        3.51219784e-04, 5.05165808e-04, 6.29735072e-05],\n",
            "       [4.95887352e-05, 6.49453729e-05, 3.22359360e-04, ...,\n",
            "        7.38392542e-05, 3.83132217e-05, 1.19484464e-04]]), 'model': StackingClassifier(cv=5,\n",
            "                   estimators=[('lr',\n",
            "                                LogisticRegression(max_iter=1000,\n",
            "                                                   random_state=42,\n",
            "                                                   solver='saga')),\n",
            "                               ('rf',\n",
            "                                RandomForestClassifier(class_weight='balanced',\n",
            "                                                       max_depth=15,\n",
            "                                                       min_samples_leaf=2,\n",
            "                                                       min_samples_split=5,\n",
            "                                                       n_estimators=200,\n",
            "                                                       random_state=42)),\n",
            "                               ('xgb',\n",
            "                                XGBClassifier(base_score=None, booster=None,\n",
            "                                              callbacks=None,\n",
            "                                              colsample_bylevel=None,\n",
            "                                              colsample_bynod...\n",
            "                                              monotone_constraints=None,\n",
            "                                              multi_strategy=None,\n",
            "                                              n_estimators=200, n_jobs=None,\n",
            "                                              num_parallel_tree=None,\n",
            "                                              random_state=42, ...)),\n",
            "                               ('bnb', BernoulliNB()),\n",
            "                               ('et',\n",
            "                                ExtraTreesClassifier(max_depth=10,\n",
            "                                                     n_estimators=200,\n",
            "                                                     random_state=42))],\n",
            "                   final_estimator=LogisticRegression(max_iter=1000,\n",
            "                                                      random_state=42,\n",
            "                                                      solver='saga'),\n",
            "                   n_jobs=-1, passthrough=True, stack_method='predict_proba')})]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = '/content/drive/MyDrive/Dataset/symbipredict_2022.csv'  # Adjust path if needed\n",
        "    top_models = run_disease_classification_pipeline(file_path)\n",
        "    print(f\"Top Models: {top_models}\")\n"
      ]
    }
  ]
}